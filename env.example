# LLMACE Environment Configuration
# 
# SETUP INSTRUCTIONS:
# 1. Copy this file:    cp env.example .env
# 2. Edit .env:         nano .env  (or your favorite editor)
# 3. Add your API keys in the .env file
# 4. Run tests:         cd tests && python quick_test.py
#
# The .env file is in .gitignore, so your keys stay private!

# ==============================================================================
# RECOMMENDED SETUP: OpenRouter + OpenAI
# ==============================================================================
# Use OpenRouter for LLM (access to many models) + OpenAI for embeddings (best quality)
# Get keys at:
#   - OpenRouter: https://openrouter.ai/keys
#   - OpenAI: https://platform.openai.com/api-keys

OPENROUTER_API_KEY=sk-or-v1-your-openrouter-key-here
OPENAI_API_KEY=sk-your-openai-api-key-here

# PRIORITY LOGIC:
# - If OPENROUTER_API_KEY exists → Use OpenRouter for LLM
# - If OPENAI_API_KEY exists → Use OpenAI for embeddings (recommended for quality)
# - If only OPENAI_API_KEY exists → Use OpenAI for both LLM and embeddings

# ==============================================================================
# ALTERNATIVE: OpenAI Only
# ==============================================================================
# If you only want to use OpenAI, just set this and comment out OPENROUTER_API_KEY:
# OPENAI_API_KEY=sk-your-openai-api-key-here

# ==============================================================================
# ALTERNATIVE: OpenRouter Only
# ==============================================================================
# If you only have OpenRouter, it will be used for both LLM and embeddings:
# OPENROUTER_API_KEY=sk-or-v1-your-openrouter-key-here
# Note: OpenAI embeddings are recommended for better quality if available

# LLM model to use for generation (choose from OpenRouter's catalog)
OPENROUTER_LLM_MODEL=x-ai/grok-2-fast

# Model for embeddings (usually OpenAI for best results)
OPENROUTER_EMBEDDING_MODEL=openai/text-embedding-3-small

# Optional: Your app/site info for OpenRouter analytics
OPENROUTER_APP_NAME=LLMACE-Testing
OPENROUTER_SITE_URL=https://github.com/yourusername/llmace

# ==============================================================================
# OPTION 3: Hybrid Setup
# ==============================================================================
# You can also mix providers:
# - Use OpenRouter for LLM (access to many models)
# - Use OpenAI directly for embeddings (often cheaper/faster)

# Uncomment these if using hybrid:
# OPENROUTER_API_KEY=sk-or-v1-your-openrouter-key-here
# OPENROUTER_LLM_MODEL=anthropic/claude-3-sonnet
# OPENAI_API_KEY=sk-your-openai-key-here
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# ==============================================================================
# Test Configuration
# ==============================================================================

# Model to use for LLM-as-a-judge evaluation
# Gemini 2.0 Flash is fast, accurate, and cost-effective for evaluation
# Why Gemini 2.0 Flash?
#   - Excellent evaluation capabilities
#   - Fast response times
#   - Cost-effective
#   - Available on OpenRouter with free tier
JUDGE_MODEL=google/gemini-2.5-flash

# Models to use in effectiveness tests (comma-separated for multiple)
# Tests will run with each model and compare results
# Default: Mix of fast (Grok 2 Fast) and powerful (GPT-4.5)
# 
# Why these models?
#   - Grok 2 Fast: Fast inference, good quality, great for iteration
#   - GPT-4.5: Highest quality, ensures LLMACE helps even top-tier models
#   - Testing both shows LLMACE generalizes across model capabilities
TEST_MODELS=x-ai/grok-2-fast,openai/google/gemini-2.5-flash.5-turbo

# Primary model for quick tests (single model, not comma-separated)
TEST_MODEL=x-ai/grok-2-fast

# Enable verbose logging during tests
LLMACE_VERBOSE=false

# ==============================================================================
# Notes
# ==============================================================================
# 
# OpenRouter Benefits:
#   ✅ Access to 100+ models from one API
#   ✅ Automatic fallback if a model is down
#   ✅ Rate limit management across providers
#   ✅ Pay-as-you-go pricing
#
# OpenRouter Pricing:
#   - Check current pricing: https://openrouter.ai/models
#   - Usually competitive with direct API access
#
# ==============================================================================
# Example Configurations
# ==============================================================================
#
# RECOMMENDED (Best Quality + Access to 100+ Models):
#   OPENROUTER_API_KEY=sk-or-v1-abc123...     # For LLM (Grok, GPT, Claude, etc.)
#   OPENAI_API_KEY=sk-abc123...               # For embeddings (best quality)
#   TEST_MODELS=x-ai/grok-2-fast,openai/google/gemini-2.5-flash.5-turbo
#   JUDGE_MODEL=google/gemini-2.5-flash
#
# OPENAI ONLY:
#   OPENAI_API_KEY=sk-abc123...               # For both LLM and embeddings
#
# OPENROUTER ONLY:
#   OPENROUTER_API_KEY=sk-or-v1-abc123...     # For both LLM and embeddings
#   TEST_MODELS=x-ai/grok-2-fast,anthropic/claude-3.5-sonnet
#   JUDGE_MODEL=google/gemini-2.5-flash
#
# ==============================================================================


